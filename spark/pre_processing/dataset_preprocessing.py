# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OqG3dGjOCnF85gAoLnRpy7nohBcWel9E
"""

import pandas as pd
import numpy as nm
import csv as cs

# Read input files

books = pd.read_csv('sample_data/books.csv', sep=';')

proceedings = pd.read_csv('sample_data/proceedings.csv')

inproceedings = pd.read_csv('sample_data/inproceedings.csv', sep=';')

incollections = pd.read_csv('sample_data/incollections.csv', sep=';')

articles = pd.read_csv('sample_data/articles.csv', sep=';')

# create table publishers
publisher = pd.DataFrame()
for index, row in books.iterrows():
    if pd.notnull(row["publisher"]):
        publisher = publisher.append({'name': row["publisher"]}, ignore_index=True)

for index, row in proceedings.iterrows():
    if pd.notnull(row["publisher"]):
        publisher = publisher.append({'name': row["publisher"]}, ignore_index=True)
publisher.drop_duplicates(subset="name", keep='first', inplace=True)

publisher.to_csv(r'publishers.csv', index=False)

# create table authors
author = pd.DataFrame()
for index, row in articles.iterrows():
    if pd.notnull(row["author"]):
        author = author.append({'name': row["author"]}, ignore_index=True)
    for i in range(1, 9, 1):
        if pd.notnull(row["author" + str(i)]):
            author = author.append({'name': row["author" + str(i)]}, ignore_index=True)

for index, row in inproceedings.iterrows():
    if pd.notnull(row["author"]):
        author = author.append({'name': row["author"]}, ignore_index=True)
    if pd.notnull(row["author.1"]):
        author = author.append({'name': row["author.1"]}, ignore_index=True)
    for i in range(2, 8, 1):
        if pd.notnull(row["author" + str(i)]):
            author = author.append({'name': row["author" + str(i)]}, ignore_index=True)

for index, row in incollections.iterrows():
    if pd.notnull(row["author"]):
        author = author.append({'name': row["author"]}, ignore_index=True)
    for i in range(1, 6, 1):
        if pd.notnull(row["author" + str(i)]):
            author = author.append({'name': row["author" + str(i)]}, ignore_index=True)

author.drop_duplicates(subset="name", keep='first', inplace=True)
print(author)

author.to_csv(r'authors.csv', index=False)

# create table editors
editor = pd.DataFrame()
for index, row in books.iterrows():
    if pd.notnull(row["editor"]):
        editor = editor.append({'name': row["editor"]}, ignore_index=True)
    for i in range(1, 4, 1):
        if pd.notnull(row["editor" + str(i)]):
            editor = editor.append({'name': row["editor" + str(i)]}, ignore_index=True)

for index, row in proceedings.iterrows():
    if pd.notnull(row["editor"]):
        editor = editor.append({'name': row["editor"]}, ignore_index=True)
    for i in range(1, 6, 1):
        if pd.notnull(row["editor" + str(i)]):
            editor = editor.append({'name': row["editor" + str(i)]}, ignore_index=True)

editor.drop_duplicates(subset="name", keep='first', inplace=True)
print(editor)

editor.to_csv(r'editors.csv', index=False)

# create table journals
journal = pd.DataFrame()
for index, row in articles.iterrows():
    if pd.notnull(row["journal"]):
        journal = journal.append({'name': row["journal"]}, ignore_index=True)

journal.drop_duplicates(subset="name", keep='first', inplace=True)
print(journal)

journal.to_csv(r'journals.csv', index=False)

# create table edited_by
edited_by = pd.DataFrame()
for index, row in books.iterrows():
    if pd.notnull(row["editor"]):
        edited_by = edited_by.append({'bookKey': row["key"], 'editor': row["editor"]}, ignore_index=True)
    for i in range(1, 4, 1):
        if pd.notnull(row["editor" + str(i)]):
            edited_by = edited_by.append({'bookKey': row["key"], 'editor': row["editor" + str(i)]}, ignore_index=True)
print(edited_by)

edited_by.to_csv(r'edited_by.csv', index=False)

# create table revised_by
revised_by = pd.DataFrame()
for index, row in proceedings.iterrows():
    if pd.notnull(row["editor"]):
        revised_by = revised_by.append({'proceedingKey': row["key"], 'editor': row["editor"]}, ignore_index=True)
    for i in range(1, 6, 1):
        if pd.notnull(row["editor" + str(i)]):
            revised_by = revised_by.append({'proceedingKey': row["key"], 'editor': row["editor" + str(i)]},
                                           ignore_index=True)
print(revised_by)

revised_by.to_csv(r'revised_by.csv', index=False)

# create table typed_by
typed_by = pd.DataFrame()
for index, row in inproceedings.iterrows():
    if pd.notnull(row["author"]):
        typed_by = typed_by.append({'inproceedingKey': row["key"], 'author': row["author"]}, ignore_index=True)
    if pd.notnull(row["author.1"]):
        typed_by = typed_by.append({'inproceedingKey': row["key"], 'author': row["author.1"]}, ignore_index=True)
    for i in range(2, 8, 1):
        if pd.notnull(row["author" + str(i)]):
            typed_by = typed_by.append({'inproceedingKey': row["key"], 'author': row["author" + str(i)]},
                                       ignore_index=True)
print(typed_by)

typed_by.to_csv(r'typed_by.csv', index=False)

# create table written_by
written_by = pd.DataFrame()
for index, row in incollections.iterrows():
    if pd.notnull(row["author"]):
        written_by = written_by.append({'incollectionKey': row["key"], 'author': row["author"]}, ignore_index=True)
    for i in range(1, 6, 1):
        if pd.notnull(row["author" + str(i)]):
            written_by = written_by.append({'incollectionKey': row["key"], 'author': row["author" + str(i)]},
                                           ignore_index=True)
print(written_by)

written_by.to_csv(r'written_by.csv', index=False)

# create table composed_by
composed_by = pd.DataFrame()
for index, row in articles.iterrows():
    if pd.notnull(row["author"]):
        composed_by = composed_by.append({'articleKey': row["key"], 'author': row["author"]}, ignore_index=True)
    for i in range(1, 9, 1):
        if pd.notnull(row["author" + str(i)]):
            composed_by = composed_by.append({'articleKey': row["key"], 'author': row["author" + str(i)]},
                                             ignore_index=True)
print(composed_by)

composed_by.to_csv(r'composed_by.csv', index=False)

# modify table incollections
incollections.drop(
    columns=["incollection_dblp100", "author", "author1", "author2", "booktitle", "__len", "author3", "author4",
             "author5", "author6", "author7", "author8"], inplace=True)
incollections.rename(columns={"crossref": "bookKey"}, inplace=True)
incollections = incollections.reindex(
    columns=["key", "title", "mdate", "year", "publtype", "pages", "url", "ee", "bookKey"])

incollections.to_csv(r'incollections.csv', index=False)

# modify table articles
articles.drop(
    columns=["Unnamed: 0", "author", "author1", "author2", "booktitle", "__len", "publtype", "cite", "ee1", "reviewid",
             "rating", "author3", "author4", "author5", "author6", "author7", "author8", "author9", "crossref"],
    inplace=True)
articles = articles.reindex(
    columns=["key", "title", "mdate", "year", "month", "cdrom", "url", "ee", "number", "volume", "pages", "journal"])

articles.to_csv(r'articles.csv', index=False)

# modify table proceedings
proceedings.drop(
    columns=["Unnamed: 0", "editor", "editor1", "booktitle", "volume", "__len", "editor2", "editor3", "editor4",
             "editor5"], inplace=True)
proceedings = proceedings.reindex(columns=["key", "title", "mdate", "year", "series", "isbn", "url", "ee", "publisher"])

proceedings.to_csv(r'proceedings.csv', index=False)

# modify table books
books.drop(columns=["ID", "author", "editor", "editor1", "note", "__len", "editor2", "editor3", "series"], inplace=True)
books = books.reindex(columns=["key", "title", "mdate", "year", "isbn", "url", "ee", "publisher"])

books.to_csv(r'books.csv', index=False)

# modify table inproceedings
inproceedings.drop(
    columns=["Unnamed: 0", "inproceedings_dblp100", "author", "author.1", "author2", "booktitle", "__len", "author3",
             "author4", "author5", "author6", "author7", "author8", "number"], inplace=True)
inproceedings.rename(columns={"crossref": "proceedingKey"}, inplace=True)
inproceedings = inproceedings.reindex(columns=["key", "title", "mdate", "year", "pages", "url", "ee", "proceedingKey"])

inproceedings.to_csv(r'inproceedings.csv', index=False)